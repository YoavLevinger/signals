install :

```
pip install fastapi uvicorn python-multipart requests pillow

ollama run llama3.2-vision

```


### run it in the background:
```
nohup ollama serve > ollama.log 2>&1 &
```